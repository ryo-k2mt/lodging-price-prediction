{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryo-k2mt/lodging-price-prediction/blob/preprocessing-v1/lodging_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b1lq56-9qee"
      },
      "source": [
        "# 目標：民泊サービスの物件データを使って、宿泊価格を予測するモデルの構築\n",
        "# 背景：\n",
        "近年、個人物件を貸し出す民泊サービスが流行っています。民泊では物件オーナーが、部屋の広さや立地をもとに宿泊価格を決めていますが、妥当な料金設定を行うのは容易ではありません。そこで今回は、民泊サービスであるAirbnbの掲載物件データを使って、宿泊価格を予測するモデルの構築にチャレンジしよう！\n",
        "\n",
        "### データ概要\n",
        "- 課題種別：回帰\n",
        "- データ種別：多変量\n",
        "- 学習データサンプル数：55583\n",
        "- 説明変数の数：27\n",
        "- 欠損値：有り"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0TN_SNW-RvM"
      },
      "source": [
        "# google drive へマウント"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mb1S7j_lpLf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE0GHPStl2VG"
      },
      "source": [
        "# ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNjnR3bZAvAs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WccaWpvmIAm"
      },
      "source": [
        "# データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsjoD2i-mK10"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/competesion_data/lodging-price-prediction/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/competesion_data/lodging-price-prediction/test.csv')\n",
        "train_copy = train_data.copy()\n",
        "test_copy = test_data.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_data.columns)"
      ],
      "metadata": {
        "id": "wrtzAH1FUrcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suuId-KvmL3N"
      },
      "source": [
        "# 前処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ04kgrL7nym"
      },
      "source": [
        "### データの確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X6FSTAY-jTW"
      },
      "outputs": [],
      "source": [
        "train_data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AisBJt8-DNMZ"
      },
      "outputs": [],
      "source": [
        "train_data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4tVsMSP72ld"
      },
      "outputs": [],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQDK0HPU75xW"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY9vHsvloksQ"
      },
      "source": [
        "固有名詞カラムや学習に影響を起こさないであろうカラムの削除"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp3e1IqfoohH"
      },
      "outputs": [],
      "source": [
        "delete_columns = ['id', 'name', 'thumbnail_url', 'zipcode']\n",
        "for delete_column in delete_columns:\n",
        "  train_data = train_data.drop(delete_column, axis=1)\n",
        "  test_data = test_data.drop(delete_column, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg1-MpiP7ivc"
      },
      "source": [
        "### 欠損値処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkcnUZ3nxIYi"
      },
      "source": [
        "欠損値の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DryzQB_17sYG"
      },
      "outputs": [],
      "source": [
        "null_counts = train_data.isnull().sum()\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(null_counts))"
      ],
      "metadata": {
        "id": "NW4odj6UWgnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxG8kWIJxLd9"
      },
      "outputs": [],
      "source": [
        "missing_value_columns = []\n",
        "for key, value in train_data.isnull().sum().iteritems():\n",
        "  if value > 0:\n",
        "    missing_value_columns.append(key)\n",
        "for column in missing_value_columns:\n",
        "  target_feature = train_data[column]\n",
        "  item_type = target_feature.dtype\n",
        "  mode = target_feature.mode()[0]\n",
        "  print(column, item_type, mode)\n",
        "  if item_type == 'object':\n",
        "    train_data[column] = train_data[column].fillna(mode)\n",
        "    # target_feature.fillna('不明')\n",
        "  else:\n",
        "    mean = target_feature.mean()\n",
        "    median = target_feature.median()\n",
        "    train_data[column] = train_data[column].fillna(mean)\n",
        "    # target_feature = target_feature.fillna(median)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3WsWEeO6_zD"
      },
      "outputs": [],
      "source": [
        "# # 最頻値で欠損値を埋める\n",
        "# for column in missing_value_columns:\n",
        "#   if column == 'review_scores_rating':\n",
        "#     continue\n",
        "#   mode = train_data[column].mode()[0]\n",
        "#   train_data[column] = train_data[column].fillna(mode)\n",
        "#   test_data[column] = test_data[column].fillna(mode)\n",
        "\n",
        "# # 平均値で欠損値を埋める\n",
        "# mode = train_data['review_scores_rating'].mean()\n",
        "# train_data['review_scores_rating'] = train_data['review_scores_rating'].fillna(mode)\n",
        "# test_data['review_scores_rating'] = test_data['review_scores_rating'].fillna(mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvKoJcaq8Mzw"
      },
      "outputs": [],
      "source": [
        "null_counts = pd.DataFrame(train_data.isnull().sum())\n",
        "null_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar0tXQg_D4S3"
      },
      "source": [
        "### 文字列要素のカラムの変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mgflr2DDyUw"
      },
      "source": [
        "- ammenities：\n",
        "- bed_type：ラベル→ラベルエンコーディング\n",
        "- cancellation_plicy：ラベル→ラベルエンコーディング\n",
        "- city：ラベル→ラベルエンコーディング\n",
        "- cleaning_fee：T/F→ラベルエンコーディング\n",
        "- description：センテンス→TF-IDFベースのベクトル化\n",
        "- first_reviw：日付→各項目でカラムを分け、数値化\n",
        "- host_has_profile_pic：T/F→ラベルエンコーディング\n",
        "- host_identity_verified：T/F→ラベルエンコーディング\n",
        "- host_response_rate：パーセント→数値を抜き出しint化。空欄は0?-1?\n",
        "- host_since：日付→各項目でカラムを分け、数値化\n",
        "- instant_bookable：T/F→ラベルエンコーディング\n",
        "- last_review：日付→各項目でカラムを分け、数値化\n",
        "- name：賃貸名→固有名詞は一旦削除\n",
        "- neighbourhood：名前？→固有名詞は一旦削除\n",
        "- property_type：ラベル→ラベルエンコーディング\n",
        "- room_type：ラベル→ラベルエンコーディング\n",
        "- thumbnail_url：URL→削除\n",
        "- zip_code：？数値ではある。（空欄あり）→"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq2M7i_ZT6r9"
      },
      "source": [
        "ラベルに対する処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-LHGZOebsOD"
      },
      "outputs": [],
      "source": [
        "\n",
        "le = LabelEncoder()\n",
        "encoding_labels = [\n",
        "    'bed_type',\n",
        "    'cancellation_policy',\n",
        "    'city',\n",
        "    'cleaning_fee',\n",
        "    'host_has_profile_pic',\n",
        "    'host_identity_verified',\n",
        "    'instant_bookable',\n",
        "    'property_type',\n",
        "    'room_type',\n",
        "    'neighbourhood'\n",
        "]\n",
        "for label in encoding_labels:\n",
        "  new_column = f'Encoded_{label}'\n",
        "  train_data[new_column] = le.fit_transform(train_data[label])\n",
        "  train_data = train_data.drop(label, axis=1)\n",
        "  test_data[new_column] = le.fit_transform(test_data[label])\n",
        "  test_data = test_data.drop(label, axis=1)\n",
        "\n",
        "\n",
        "train_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyYknCyoT_c3"
      },
      "source": [
        "日付データに対する処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NcKoFv_UCEW"
      },
      "outputs": [],
      "source": [
        "# 要素か年月日を取得する関数\n",
        "def extract_YMD(df, target_column):\n",
        "  # df[target_column] = df[target_column].fillna('0000-00-00')\n",
        "  # year_column = f'{target_column}_year'\n",
        "  # month_column = f'{target_column}_month'\n",
        "  # day_column = f'{target_column}_day'\n",
        "  # df[[year_column, month_column, day_column]] = df[target_column].str.split('-', expand=True).astype(int)\n",
        "  df = df.drop(target_column, axis=1)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0s1reFPMJ45"
      },
      "outputs": [],
      "source": [
        "date_columns = [\n",
        "    'first_review',\n",
        "    'host_since',\n",
        "    'last_review'\n",
        "]\n",
        "for column in date_columns:\n",
        "  # 各要素は YYYY/MM/DD\n",
        "  train_data = extract_YMD(train_data, column)\n",
        "  test_data = extract_YMD(test_data, column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5WbTED7Z8jq"
      },
      "source": [
        "amenities の処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zNBTV2lVNfM"
      },
      "outputs": [],
      "source": [
        "# amenities を　文字列からリストへ変換\n",
        "amenities = []\n",
        "for material in train_data['amenities']:\n",
        "  for replace_str in ['{', '}', '\"']:\n",
        "    material = material.replace(replace_str, '')\n",
        "  material = material.split(',')\n",
        "  amenities.append(material)\n",
        "train_data['amenities'] = amenities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lhA9I_7l9ro"
      },
      "outputs": [],
      "source": [
        "# アメニティ列をexplodeして、各アメニティごとに行を作成\n",
        "amenities_exploded = train_data['amenities'].explode()\n",
        "\n",
        "# explodeしたデータを使ってワンホットエンコーディング\n",
        "onehot_encoded = pd.get_dummies(amenities_exploded).groupby(level=0).sum()\n",
        "\n",
        "# 元のデータフレームにワンホットエンコーディングしたデータを結合\n",
        "train_data = pd.concat([train_data, onehot_encoded], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad0TtUICkGFR"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.drop('amenities', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFJ16R10n_t_"
      },
      "source": [
        "hosted_response_rate の処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwKOtJQEn1O3"
      },
      "outputs": [],
      "source": [
        "host_response_rate_mode = train_data['host_response_rate'].mode()[0]\n",
        "\n",
        "# 最頻値で補完する\n",
        "train_data['host_response_rate'] = train_data['host_response_rate'].fillna(host_response_rate_mode)\n",
        "test_data['host_response_rate'] = test_data['host_response_rate'].fillna(host_response_rate_mode)\n",
        "\n",
        "print(train_data['host_response_rate'].isnull().sum())\n",
        "\n",
        "# 要素に % が含まれるので、削除し int 型へ変換する。\n",
        "train_data['host_response_rate'] = train_data['host_response_rate'].str.replace('%', '').astype(int)\n",
        "train_data['host_response_rate'].dtype\n",
        "test_data['host_response_rate'] = test_data['host_response_rate'].str.replace('%', '').astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu7P0OJKoeZh"
      },
      "source": [
        "description の処理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3FUjlXgoaMQ"
      },
      "outputs": [],
      "source": [
        "## TFIFF を使用して文字列を変換したいが、 toarray 関数でセクションがクラッシュしてしまうので、description 列はとりあえず削除する方向で進める。\n",
        "train_data = train_data.drop('description', axis=1)\n",
        "test_data = test_data.drop('description', axis=1)\n",
        "# tfidvectorizer = TfidfVectorizer()\n",
        "# # train_data の変換\n",
        "# train_tfid_matrix = tfidvectorizer.fit_transform(train_data['description'])\n",
        "# train_data['description'] = train_tfid_matrix.toarray()\n",
        "# # test_data の変換\n",
        "# test_tfid_matrix = tfidvectorizer.transform(test_data['description'])\n",
        "# test_data['description'] = test_tfid_matrix.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsdvXUlTw_Yh"
      },
      "source": [
        "要素が文字列の列がないかの最終確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXSBcn_kPN9"
      },
      "outputs": [],
      "source": [
        "object_columns = train_data.dtypes[train_data.dtypes == 'object'].index.tolist()\n",
        "object_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i86fF_bn9j_M"
      },
      "source": [
        "# 損失関数の定義\n",
        "→ sickit learn を使用する場合はモデルに組み込まれているためいらない。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ei1pOD-mPgH"
      },
      "source": [
        "# データの分割"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = train_data['y'].astype(int)\n",
        "train_data = train_data.drop('y', axis=1)"
      ],
      "metadata": {
        "id": "aBnTXV_K--t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHV6VIwRBFIw"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, t_train, t_val = train_test_split(train_data, t, train_size=0.8, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pabyXPdhAfTj"
      },
      "source": [
        "# 正規化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIhXYEMvAhw1"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_val = scaler.transform(x_val)\n",
        "# test_data = scaler.transform(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySKhDgkzmVT7"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#　モデルの選択\n",
        "from sklearn.linear_model import SGDClassifier, LinearRegression, SGDRegressor\n",
        "\n",
        "# model = SGDClassifier(loss='log_loss', random_state=0)\n",
        "model = LinearRegression()\n",
        "# model = SGDRegressor(max_iter=100, tol=1e-3, penalty=None, eta0=0.01, random_state=0)"
      ],
      "metadata": {
        "id": "w27xA_MkQVkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9OZspfomU4V"
      },
      "outputs": [],
      "source": [
        "# 学習実行\n",
        "model.fit(x_train, t_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZBs4qj2BZ9b"
      },
      "source": [
        "# 性能評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1C3-irvBYnM"
      },
      "outputs": [],
      "source": [
        "train_score = model.score(x_train, t_train)\n",
        "print(f\"Train score: {train_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coef = model.coef_\n",
        "columns = train_data.columns\n",
        "features_importances = zip(columns, coef)\n",
        "sorted_features = sorted(features_importances, key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "# データの準備\n",
        "labels, values = zip(*sorted_features)\n",
        "\n",
        "plt.figure(figsize=(8, 30))\n",
        "# 棒グラフのプロット\n",
        "plt.barh(range(len(labels)), values, align='center')\n",
        "plt.yticks(range(len(labels)), labels)\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance')\n",
        "plt.gca().invert_yaxis()  # グラフを重要度の高い順に表示\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p-ZQkoLxTGRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqA4s6qJmYr1"
      },
      "source": [
        "# 推論"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred = model.predict(x_val)"
      ],
      "metadata": {
        "id": "D1ZYXuW2gOQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 回帰モデルの評価\n",
        "val_r2 = r2_score(t_val, val_pred)\n",
        "print(f'Validation R^2:\" {round(val_r2, 2)}')"
      ],
      "metadata": {
        "id": "bYzilpxOgD77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W0SAJKPmb47"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1ybRkT-SYvAtIvmizmGrfa-ZPt-ssI4R7",
      "authorship_tag": "ABX9TyPKxdl92S70JXFEI2dHFEU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}